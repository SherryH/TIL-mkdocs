Figuring out how to make the browser reads out the mp3 file takes a bit of time

## Web Speech API vs Goolgle TTS or Azure TTS
- Web Speech API is a browser standard. It is up to each individual browser to implement the functionalities according to the standard. 
- See [Firefox implementation](https://wiki.mozilla.org/Web_Speech_API_-_Speech_Recognition). FF uses Google TTS in the background to transcribe speech and synthesis text.
- The voice quality seem different even though Web Speech API uses the same Google TTS engine in the background. Comparing the voice mp3 generated from Google TTS API and Web Speech API [Codepen demo](https://codepen.io/sgestrella/pen/QodzgY) - Google TTS API seem better... even after setting the speech speed to 1.0 for the Web API demo

### Google TTS
There are 2 tts, one is using the TTS API, another one is using the Google Translate API.
#### Google Translate URL
- Github search only yields results with JS and Google Translate TTS 
- https://github.com/zlargon/google-tts/blob/master/src/getAudioBase64.ts
- Basically this one is easier. I can just use Google translate API, without worrying about the API keys etc.
- Check if there is wordlimit, if i can change the voices

#### Google TTS API
- The example tells us how to export the text into a read out mp3 file
- How to make the browser read the mp3 without generating millions of mp3 files?
- According to [GTTS library](https://github.com/thiennq/node-gtts/blob/master/index.js) (youtube tutorial), people use writeStream to get the sound file instead of writeFile.
- NOTE: No matter it is with writeStream or writeFile, the server would always outputs a ==mp3 file== and send it over to the browser via http response
- Figure out how to stream the voice from nodeJS to browser via response




### TODO:
1. From current setting, figuring out how to send stream mp3 voice to browser via response
``` js
fs.createReadStream(filePath).pipe(response);
```
2. Design the Data structure, table schema and API (or maybe just read from the file system for now) (maybe db is easier after deploy)
3. Work on seaprate parts: 
4. connect with MongoDB, - get ex working
5. connect with S3 - get ex working



### Observation
- it doesn't matter if it is write to stream or writeFile, we still need to output a mp3 and enable browser to read the file. This is what Web Speech API does under the hood.
- a short 10s mp3 is 30kb, like the size of an icon. It is ok to save the mp3 in the github for now.


#### To play audio on click
``` js
  const playSound = () => {
    const audio = new Audio('/output_m.mp3');
    audio.play();
  };
```

#### NextJS + MongoDB
https://www.mongodb.com/developer/how-to/nextjs-with-mongodb/
https://github.com/rivera1294/next-mongodb/blob/master/pages/new.js
https://github.com/KaterinaLupacheva/my-projects-dashboard/blob/master/pages/api/stats/index.ts

#### NextJS + S3
- for storing binary files like mp3 or images
https://github.com/leerob/nextjs-aws-s3

#### Use Firebase?
- Firebase DB is like Mongo but we can store everything under Google instead of in different places?
- So, Firebase provides functions and storage DBs
- AWS s3: after 12month, no more Free tier. So try out Frebase
- Google Cloud storage: Always free for US region. https://cloud.google.com/storage/pricing#price-tables so use it for now
- Cloud Firestore vs realtime DB: similar, use Cloud Firestore for storing the convo JSON
- Cloud Storage: storing the mp3

##### What is Firebase comprised of now?
- Cloud functions? DB? Storage?
- - DB: Firestore
- We can push NextJS to Firebase 
- Tutorial Mar 2021: https://www.youtube.com/watch?v=SYnu6CLKD70
